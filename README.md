# NLP Lab 2: Regex and Word Embedding

**Instructor**: Pr. Lotfi Elaachak  
**Course**: Master AISD, Département Génie Informatique  
**University**: Université Abdelmalek Essaadi, Faculté des Sciences et Techniques de Tanger  
**Student**: NOUIH Omar

## Objective

The primary goal of this lab is to introduce students to Natural Language Processing (NLP) techniques, focusing on Rule-based NLP, Regex, and Word Embedding.

## Part 1: Rule-Based NLP and Regex

### Task Description

Implement Python code using Regex to generate a bill from the provided text. The code should be able to extract product names, quantities, and prices to calculate total costs.

### Example

**Input**: "I bought three Samsung smartphones at $150 each, four kilos of fresh bananas for $1.2 a kilogram, and one Hamburger for $4.5."  
**Expected Output**: A table displaying the product, quantity, unit price, and total price.

### Implementation

The implementation involves using Regex to extract relevant information from the text and calculating the total bill based on the extracted data.

## Part 2: Word Embedding Techniques

### Techniques Covered

1. One Hot Encoding
2. Bag of Words
3. TF-IDF
4. Word2Vec Approaches (Skip Gram, CBOW)
5. GloVe and FastText

### Visualization and Evaluation

Apply the t-SNE algorithm to visualize the word embeddings generated by each technique and evaluate their effectiveness in capturing semantic information.

---

# NLP Lab 2: Regex and Word Embedding

**Instructor**: Pr. Lotfi Elaachak  
**Course**: Master AISD, Département Génie Informatique  
**University**: Université Abdelmalek Essaadi, Faculté des Sciences et Techniques de Tanger  
**Student**: NOUIH Omar

## Objective

The primary goal of this lab is to introduce students to Natural Language Processing (NLP) techniques, focusing on Rule-based NLP, Regex, and Word Embedding.

## Part 1: Rule-Based NLP and Regex

### Task Description

Implement Python code using Regex to generate a bill from the provided text. The code should be able to extract product names, quantities, and prices to calculate total costs.

### Example

**Input**: "I bought three Samsung smartphones at $150 each, four kilos of fresh bananas for $1.2 a kilogram, and one Hamburger for $4.5."  
**Expected Output**: A table displaying the product, quantity, unit price, and total price.

### Implementation

The implementation involves using Regex to extract relevant information from the text and calculating the total bill based on the extracted data.

## Part 2: Word Embedding Techniques

### Techniques Covered

1. One Hot Encoding
2. Bag of Words
3. TF-IDF
4. Word2Vec Approaches (Skip Gram, CBOW)
5. FastText

### Visualization and Evaluation

Apply the t-SNE algorithm to visualize the word embeddings generated by each technique and evaluate their effectiveness in capturing semantic information.

---

**Notebook Overview**:

The notebook contains detailed implementations and explanations for each part of the lab. It begins with the implementation of Regex for bill generation and proceeds to cover various Word Embedding techniques, including One Hot Encoding, Bag of Words, TF-IDF, Skip Gram, CBOW, and FastText. Each technique is accompanied by code examples, visualizations, and discussions on their effectiveness.

**Downloading Pre-trained Models**:

1. **Word2Vec (CBOW)**: Download the pre-trained CBOW Word2Vec model from [link](https://github.com/mmdoha200/ArWordVec) and place it in the same directory as the notebook.
2. **Word2Vec (Skip Gram)**: Download the pre-trained Skip Gram Word2Vec model from [link](https://github.com/mmdoha200/ArWordVec) and place it in the same directory as the notebook.
3. **FastText**: Download the pre-trained FastText model from [link](https://fasttext.cc/docs/en/crawl-vectors.html) and place it in the same directory as the notebook.
